{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: This is just for using the local whisper dir as the package directly. Delete until next comment when just installing whisper normally.\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path(os.path.abspath('')).resolve().parents[1]))\n",
    "# end of dev import\n",
    "import whisper\n",
    "\n",
    "import colorsys\n",
    "from typing import List\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from IPython.display import HTML as html_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"assets/230901_10min.wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device) # make log-Mel spectrogram and move to the same device as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_lang = False\n",
    "language = \"en\"\n",
    "if detect_lang: # detect the spoken language\n",
    "    print('Detecting language')\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    language=max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colored_text(tokens: List[int], token_probs: List[float], tokenizer, prompt: str=\"\"):\n",
    "    text_tokens = [tokenizer.decode([t]) for t in tokens]\n",
    "\n",
    "    output_text = \"\"\n",
    "    for i, (token, prob) in enumerate(zip(text_tokens, token_probs)):\n",
    "        # Interpolate between red and green in the HSV color space\n",
    "        r, g, b = colorsys.hsv_to_rgb(prob * (1/3), 1, 1)\n",
    "        r, g, b = int(r * 255), int(g * 255), int(b * 255)\n",
    "        color_code = f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "\n",
    "        colored_token = f\"<text style=color:{color_code}>{token}</text>\"\n",
    "        output_text += colored_token\n",
    "\n",
    "    return output_text\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer(multilingual=model.is_multilingual, language=language, task=options.task)\n",
    "html_print(get_colored_text(result.tokens, result.token_probs, tokenizer))  # print text with fancy confidence colors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
